\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage[utf8]{inputenc}
% Copyright
\setcopyright{none}
\editor{Alexander Acosta}
\editor{Julián Arango}
\settopmatter{printacmref=false}
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\begin{document}
\title{Clústering de Documentos a partir de Métricas de Similitud}
\subtitle{Big Data}
% \subtitlenote{Proyecto realizado para el modulo de Big Data en la materia
%   tópicos especiales en telemática, Ingeniería de Sistemas, Universidad EAFIT, 2017-2.}


\author{Alexander Acosta Jiménez}
\affiliation{%
  \institution{Universidad EAFIT}
  \city{Medellín}
  \state{Colombia}
  }
\email{aacosta8@eafit.edu.co}

\author{Julián David Arango López}
\affiliation{%
\institution{Universidad EAFIT}
\city{Medellín}
\state{Colombia}
}
\email{jarangol@eafit.edu.co}

\renewcommand{\shortauthors}{Acosta, Arango}

\begin{abstract}
El análisis de datos es un problema que ha sido estudiado por diversos campos,
actualmente este campo es abarcado principalmente por ciencias de la computación
y estadística debido al gran volumen de información y a la popularización del
uso del computador para almacenar información.

El manejo de un gran volumen de información requiere una adecuada infraestructura
y uso de recursos, en esta aproximación se busca aplicar herramientas
especializadas en el manejo de datos de gran volumen y algoritmos complejos,
en el análisis de datos, específicamente en el agrupamiento (clústering)
de documentos, utilizando  el algoritmo de machine learning K-means,
se implementa una solución no interactiva en Python 2.7, que utiliza la
arquitectura brindada por el framework Spark, para ser ejecutada en un ecosistema
Hadoop.

Como se resultado se comparan las implementaciones y los resultados obtenidos
entre HPC y Big data, utilizando datasets de ejemplo como Gutenberg.
\end{abstract}
% \footnote{This is an abstract footnote} How to do foot note
%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002944.10011123.10010916</concept_id>
<concept_desc>General and reference~Measurement</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002944.10011123.10010912</concept_id>
<concept_desc>General and reference~Empirical studies</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010169</concept_id>
<concept_desc>Computing methodologies~Parallel computing methodologies</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Measurement}
\ccsdesc[300]{General and reference~Empirical studies}
\ccsdesc[500]{Computing methodologies~Parallel computing methodologies}

\keywords{Big Data, Distributed Computing,
K-means, Intensive Computation, Intensive Data, Machine Learning,
  Data Mining, Clustering}
\maketitle

\input{body}
% \bibliographystyle{ACM-Reference-Format}
% \bibliography{sample-bibliography}

\end{document}
